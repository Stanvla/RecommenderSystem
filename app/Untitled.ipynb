{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import train_dev_test_split, read_data\n",
    "from CollaborativeFiltering import CollaborativeFilteringModel\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data and create training, development and testning sets, for hyperparams selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating test set:  43%|█████       | 489086/1149780 [00:26<00:35, 18489.86it/s]\n",
      "Creating dev set: 100%|████████████| 1149780/1149780 [01:11<00:00, 16116.18it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data/'\n",
    "csv_zip = 'BX-CSV-Dump.zip'\n",
    "ratings_pkl = 'data/ratings.pkl'\n",
    "ratings_csv = 'data/new_ratings.csv'\n",
    "seed = 0xDEAD\n",
    "\n",
    "# function already returns ratings with the book titles\n",
    "# if ISBN was not found, the title would be `Unknown Book`\n",
    "ratings_df, ratings = read_data(\n",
    "    data_dir=data_dir,\n",
    "    csv_zip=csv_zip,\n",
    "    ratings_pickle=ratings_pkl,\n",
    "    csv_fn=ratings_csv,\n",
    ")\n",
    "\n",
    "train, dev, test = train_dev_test_split(\n",
    "    ratings_df=ratings_df,\n",
    "    test_perc=0.2,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>rating</th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Rites of Passage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>The Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Help!: Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>The Amsterdam Connection : Level 4 (Cambridge ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        ISBN  rating  book_id  \\\n",
       "0        0  034545104X       0        0   \n",
       "1        1  0155061224       5        1   \n",
       "2        2  0446520802       0        2   \n",
       "3        3  052165615X       3        3   \n",
       "4        3  0521795028       6        4   \n",
       "\n",
       "                                               title  \n",
       "0                               Flesh Tones: A Novel  \n",
       "1                                   Rites of Passage  \n",
       "2                                       The Notebook  \n",
       "3                                     Help!: Level 1  \n",
       "4  The Amsterdam Connection : Level 4 (Cambridge ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select best hyperparams using validation set. Training will be done on small number of epochs. The learning rate and learning rate factor were set by trial and error on previous runs, obiously they highly depend on the other parameters, however for simplicity i left them fixed. Logging is done every second epoch to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for lambda :: 2, n_features :: 6\n",
      "Epoch   0, min MSE loss 9.024, curr MSE loss 9.013, last 2 epochs took 13.993 secs, elapsed 0.233 mins\n",
      "Epoch   2, min MSE loss 9.013, curr MSE loss 8.919, last 2 epochs took 19.058 secs, elapsed 0.551 mins\n",
      "Epoch   4, min MSE loss 8.919, curr MSE loss 8.339, last 2 epochs took 20.227 secs, elapsed 0.888 mins\n",
      "Epoch   6, min MSE loss 8.339, curr MSE loss 7.693, last 2 epochs took 20.463 secs, elapsed 1.229 mins\n",
      "Epoch   8, min MSE loss 7.693, curr MSE loss 7.349, last 2 epochs took 20.413 secs, elapsed 1.569 mins\n",
      "Train RMSE :: 3.634029159042763\n",
      "\n",
      "Training for lambda :: 2, n_features :: 9\n",
      "Epoch   0, min MSE loss 9.037, curr MSE loss 9.019, last 2 epochs took 14.881 secs, elapsed 0.248 mins\n",
      "Epoch   2, min MSE loss 9.019, curr MSE loss 8.892, last 2 epochs took 20.516 secs, elapsed 0.590 mins\n",
      "Epoch   4, min MSE loss 8.892, curr MSE loss 8.209, last 2 epochs took 20.202 secs, elapsed 0.927 mins\n",
      "Epoch   6, min MSE loss 8.209, curr MSE loss 7.465, last 2 epochs took 20.380 secs, elapsed 1.266 mins\n",
      "Epoch   8, min MSE loss 7.465, curr MSE loss 6.985, last 2 epochs took 20.189 secs, elapsed 1.603 mins\n",
      "Train RMSE :: 3.363778361150706\n",
      "\n",
      "Training for lambda :: 2, n_features :: 12\n",
      "Epoch   0, min MSE loss 9.049, curr MSE loss 9.026, last 2 epochs took 14.858 secs, elapsed 0.248 mins\n",
      "Epoch   2, min MSE loss 9.026, curr MSE loss 8.854, last 2 epochs took 20.051 secs, elapsed 0.582 mins\n",
      "Epoch   4, min MSE loss 8.854, curr MSE loss 7.965, last 2 epochs took 20.320 secs, elapsed 0.920 mins\n",
      "Epoch   6, min MSE loss 7.965, curr MSE loss 7.218, last 2 epochs took 20.250 secs, elapsed 1.258 mins\n",
      "Epoch   8, min MSE loss 7.218, curr MSE loss 6.999, last 2 epochs took 23.186 secs, elapsed 1.644 mins\n",
      "Train RMSE :: 3.380469750404126\n",
      "\n",
      "Training for lambda :: 1, n_features :: 6\n",
      "Epoch   0, min MSE loss 9.012, curr MSE loss 9.001, last 2 epochs took 14.772 secs, elapsed 0.246 mins\n",
      "Epoch   2, min MSE loss 9.001, curr MSE loss 8.905, last 2 epochs took 20.966 secs, elapsed 0.596 mins\n",
      "Epoch   4, min MSE loss 8.905, curr MSE loss 8.306, last 2 epochs took 20.629 secs, elapsed 0.939 mins\n",
      "Epoch   6, min MSE loss 8.306, curr MSE loss 7.641, last 2 epochs took 20.346 secs, elapsed 1.279 mins\n",
      "Epoch   8, min MSE loss 7.641, curr MSE loss 7.292, last 2 epochs took 20.580 secs, elapsed 1.622 mins\n",
      "Train RMSE :: 3.6353903432040098\n",
      "\n",
      "Training for lambda :: 1, n_features :: 9\n",
      "Epoch   0, min MSE loss 9.019, curr MSE loss 9.002, last 2 epochs took 15.251 secs, elapsed 0.254 mins\n",
      "Epoch   2, min MSE loss 9.002, curr MSE loss 8.871, last 2 epochs took 20.371 secs, elapsed 0.594 mins\n",
      "Epoch   4, min MSE loss 8.871, curr MSE loss 8.163, last 2 epochs took 20.635 secs, elapsed 0.938 mins\n",
      "Epoch   6, min MSE loss 8.163, curr MSE loss 7.393, last 2 epochs took 20.491 secs, elapsed 1.279 mins\n",
      "Epoch   8, min MSE loss 7.393, curr MSE loss 6.897, last 2 epochs took 20.797 secs, elapsed 1.626 mins\n",
      "Train RMSE :: 3.346141147740494\n",
      "\n",
      "Training for lambda :: 1, n_features :: 12\n",
      "Epoch   0, min MSE loss 9.025, curr MSE loss 9.003, last 2 epochs took 14.789 secs, elapsed 0.246 mins\n",
      "Epoch   2, min MSE loss 9.003, curr MSE loss 8.826, last 2 epochs took 20.656 secs, elapsed 0.591 mins\n",
      "Epoch   4, min MSE loss 8.826, curr MSE loss 7.907, last 2 epochs took 20.366 secs, elapsed 0.930 mins\n",
      "Epoch   6, min MSE loss 7.907, curr MSE loss 7.136, last 2 epochs took 20.398 secs, elapsed 1.270 mins\n",
      "Epoch   8, min MSE loss 7.136, curr MSE loss 6.927, last 2 epochs took 20.023 secs, elapsed 1.604 mins\n",
      "Train RMSE :: 3.4081884617083125\n",
      "\n",
      "Training for lambda :: 0.1, n_features :: 6\n",
      "Epoch   0, min MSE loss 9.001, curr MSE loss 8.991, last 2 epochs took 15.028 secs, elapsed 0.250 mins\n",
      "Epoch   2, min MSE loss 8.991, curr MSE loss 8.890, last 2 epochs took 21.015 secs, elapsed 0.601 mins\n",
      "Epoch   4, min MSE loss 8.890, curr MSE loss 8.273, last 2 epochs took 20.014 secs, elapsed 0.934 mins\n",
      "Epoch   6, min MSE loss 8.273, curr MSE loss 7.590, last 2 epochs took 20.861 secs, elapsed 1.282 mins\n",
      "Epoch   8, min MSE loss 7.590, curr MSE loss 7.236, last 2 epochs took 19.658 secs, elapsed 1.610 mins\n",
      "Train RMSE :: 3.638178309471748\n",
      "\n",
      "Training for lambda :: 0.1, n_features :: 9\n",
      "Epoch   0, min MSE loss 9.002, curr MSE loss 8.986, last 2 epochs took 14.567 secs, elapsed 0.243 mins\n",
      "Epoch   2, min MSE loss 8.986, curr MSE loss 8.849, last 2 epochs took 20.057 secs, elapsed 0.577 mins\n",
      "Epoch   4, min MSE loss 8.849, curr MSE loss 8.117, last 2 epochs took 19.590 secs, elapsed 0.904 mins\n",
      "Epoch   6, min MSE loss 8.117, curr MSE loss 7.322, last 2 epochs took 19.772 secs, elapsed 1.233 mins\n",
      "Epoch   8, min MSE loss 7.322, curr MSE loss 6.810, last 2 epochs took 20.218 secs, elapsed 1.570 mins\n",
      "Train RMSE :: 3.3303730787566344\n",
      "\n",
      "Training for lambda :: 0.1, n_features :: 12\n",
      "Epoch   0, min MSE loss 9.003, curr MSE loss 8.981, last 2 epochs took 14.815 secs, elapsed 0.247 mins\n",
      "Epoch   2, min MSE loss 8.981, curr MSE loss 8.798, last 2 epochs took 20.503 secs, elapsed 0.589 mins\n",
      "Epoch   4, min MSE loss 8.798, curr MSE loss 7.849, last 2 epochs took 20.244 secs, elapsed 0.926 mins\n",
      "Epoch   6, min MSE loss 7.849, curr MSE loss 7.057, last 2 epochs took 20.173 secs, elapsed 1.262 mins\n",
      "Epoch   8, min MSE loss 7.057, curr MSE loss 6.932, last 2 epochs took 20.406 secs, elapsed 1.602 mins\n",
      "Train RMSE :: 3.426671996325247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for lam in [2, 1, 0.1]:\n",
    "    for n_ft in [6, 9, 12]:\n",
    "        print(f'Training for lambda :: {lam}, n_features :: {n_ft}')\n",
    "        m = CollaborativeFilteringModel(\n",
    "            ratings=train,\n",
    "            n_users=ratings_df.user_id.max() + 1,\n",
    "            n_items=ratings_df.book_id.max() + 1,\n",
    "            n_features=n_ft,\n",
    "            mean_norm=True,\n",
    "        )\n",
    "\n",
    "\n",
    "        rmse, min_loss, cur_loss = m.train(\n",
    "            lam=lam,\n",
    "            lr=0.015,\n",
    "            lr_factor=0.85,\n",
    "            n_epochs=10,\n",
    "            seed=seed,\n",
    "            log_each=2,\n",
    "        )\n",
    "        \n",
    "        rmse_val = m.evaluate_rmse(dev)\n",
    "        results.append(dict(rmse_val=rmse_val, rmse_train=rmse, lamb=lam, n_features=n_ft))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_val</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>lamb</th>\n",
       "      <th>n_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.652924</td>\n",
       "      <td>3.363778</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.667651</td>\n",
       "      <td>3.346141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.681516</td>\n",
       "      <td>3.330373</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.734767</td>\n",
       "      <td>3.380470</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.746713</td>\n",
       "      <td>3.634029</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.768721</td>\n",
       "      <td>3.635390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.784279</td>\n",
       "      <td>3.408188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.789873</td>\n",
       "      <td>3.638178</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.844285</td>\n",
       "      <td>3.426672</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rmse_val  rmse_train  lamb  n_features\n",
       "1  11.652924    3.363778   2.0           9\n",
       "4  11.667651    3.346141   1.0           9\n",
       "7  11.681516    3.330373   0.1           9\n",
       "2  11.734767    3.380470   2.0          12\n",
       "0  11.746713    3.634029   2.0           6\n",
       "3  11.768721    3.635390   1.0           6\n",
       "5  11.784279    3.408188   1.0          12\n",
       "6  11.789873    3.638178   0.1           6\n",
       "8  11.844285    3.426672   0.1          12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).sort_values(by='rmse_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0, min MSE loss 9.419, curr MSE loss 9.407, last 2 epochs took 15.370 secs, elapsed 0.256 mins\n",
      "Epoch   2, min MSE loss 9.407, curr MSE loss 9.343, last 2 epochs took 20.577 secs, elapsed 0.599 mins\n",
      "Epoch   4, min MSE loss 9.343, curr MSE loss 9.012, last 2 epochs took 25.948 secs, elapsed 1.032 mins\n",
      "Epoch   6, min MSE loss 9.012, curr MSE loss 8.573, last 2 epochs took 25.691 secs, elapsed 1.460 mins\n",
      "Epoch   8, min MSE loss 8.573, curr MSE loss 8.163, last 2 epochs took 26.778 secs, elapsed 1.906 mins\n",
      "Epoch  10, min MSE loss 8.163, curr MSE loss 7.866, last 2 epochs took 25.255 secs, elapsed 2.327 mins\n",
      "Epoch  12, min MSE loss 7.866, curr MSE loss 7.661, last 2 epochs took 27.121 secs, elapsed 2.779 mins\n",
      "Epoch  14, min MSE loss 7.661, curr MSE loss 7.519, last 2 epochs took 25.374 secs, elapsed 3.202 mins\n",
      "Epoch  16, min MSE loss 7.519, curr MSE loss 7.420, last 2 epochs took 24.048 secs, elapsed 3.603 mins\n",
      "Epoch  18, min MSE loss 7.420, curr MSE loss 7.350, last 2 epochs took 25.661 secs, elapsed 4.030 mins\n",
      "Epoch  20, min MSE loss 7.350, curr MSE loss 7.302, last 2 epochs took 25.931 secs, elapsed 4.463 mins\n",
      "Epoch  22, min MSE loss 7.302, curr MSE loss 7.267, last 2 epochs took 26.994 secs, elapsed 4.912 mins\n",
      "Epoch  24, min MSE loss 7.267, curr MSE loss 7.242, last 2 epochs took 28.451 secs, elapsed 5.387 mins\n",
      "Train RMSE :: 3.5747384178280313\n"
     ]
    }
   ],
   "source": [
    "lam = 2\n",
    "n_features = 9\n",
    "\n",
    "m = CollaborativeFilteringModel(\n",
    "    ratings={**train, **dev},\n",
    "    n_users=ratings_df.user_id.max() + 1,\n",
    "    n_items=ratings_df.book_id.max() + 1,\n",
    "    n_features=n_features,\n",
    "    mean_norm=True,\n",
    ")\n",
    "\n",
    "\n",
    "rmse, min_loss, cur_loss = m.train(\n",
    "    lam=lam,\n",
    "    lr=0.01,\n",
    "    lr_factor=0.8475,\n",
    "    n_epochs=25,\n",
    "    seed=seed,\n",
    "    log_each=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the best model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.175313177224092"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_test = m.evaluate_rmse(test)\n",
    "rmse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the best model on the whole data available, and then use it to predict recomendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0, min MSE loss 9.840, curr MSE loss 9.831, last 2 epochs took 21.395 secs, elapsed 0.357 mins\n",
      "Epoch   2, min MSE loss 9.831, curr MSE loss 9.768, last 2 epochs took 28.471 secs, elapsed 0.831 mins\n",
      "Epoch   4, min MSE loss 9.768, curr MSE loss 9.469, last 2 epochs took 29.015 secs, elapsed 1.315 mins\n",
      "Epoch   6, min MSE loss 9.469, curr MSE loss 9.148, last 2 epochs took 28.903 secs, elapsed 1.796 mins\n",
      "Epoch   8, min MSE loss 9.148, curr MSE loss 8.808, last 2 epochs took 28.363 secs, elapsed 2.269 mins\n",
      "Epoch  10, min MSE loss 8.808, curr MSE loss 8.554, last 2 epochs took 28.560 secs, elapsed 2.745 mins\n",
      "Epoch  12, min MSE loss 8.554, curr MSE loss 8.372, last 2 epochs took 28.143 secs, elapsed 3.214 mins\n",
      "Epoch  14, min MSE loss 8.372, curr MSE loss 8.243, last 2 epochs took 27.856 secs, elapsed 3.678 mins\n",
      "Epoch  16, min MSE loss 8.243, curr MSE loss 8.152, last 2 epochs took 28.222 secs, elapsed 4.149 mins\n",
      "Epoch  18, min MSE loss 8.152, curr MSE loss 8.088, last 2 epochs took 28.094 secs, elapsed 4.617 mins\n",
      "Epoch  20, min MSE loss 8.088, curr MSE loss 8.042, last 2 epochs took 27.078 secs, elapsed 5.068 mins\n",
      "Epoch  22, min MSE loss 8.042, curr MSE loss 8.010, last 2 epochs took 26.755 secs, elapsed 5.514 mins\n",
      "Epoch  24, min MSE loss 8.010, curr MSE loss 7.987, last 2 epochs took 26.633 secs, elapsed 5.958 mins\n",
      "Epoch  26, min MSE loss 7.987, curr MSE loss 7.970, last 2 epochs took 22.911 secs, elapsed 6.340 mins\n",
      "Epoch  28, min MSE loss 7.970, curr MSE loss 7.958, last 2 epochs took 22.590 secs, elapsed 6.717 mins\n",
      "Epoch  30, min MSE loss 7.958, curr MSE loss 7.950, last 2 epochs took 22.866 secs, elapsed 7.098 mins\n",
      "Epoch  32, min MSE loss 7.950, curr MSE loss 7.944, last 2 epochs took 22.994 secs, elapsed 7.481 mins\n",
      "Epoch  34, min MSE loss 7.944, curr MSE loss 7.940, last 2 epochs took 23.063 secs, elapsed 7.865 mins\n",
      "Epoch  36, min MSE loss 7.940, curr MSE loss 7.936, last 2 epochs took 25.070 secs, elapsed 8.283 mins\n",
      "Epoch  38, min MSE loss 7.936, curr MSE loss 7.934, last 2 epochs took 24.385 secs, elapsed 8.689 mins\n",
      "Train RMSE :: 3.935127921102691\n"
     ]
    }
   ],
   "source": [
    "lam = 2\n",
    "n_features = 9\n",
    "\n",
    "m = CollaborativeFilteringModel(\n",
    "    ratings={**train, **dev, **test},\n",
    "    n_users=ratings_df.user_id.max() + 1,\n",
    "    n_items=ratings_df.book_id.max() + 1,\n",
    "    n_features=n_features,\n",
    "    mean_norm=True,\n",
    ")\n",
    "\n",
    "\n",
    "rmse, min_loss, cur_loss = m.train(\n",
    "    lam=lam,\n",
    "    lr=0.0075,\n",
    "    lr_factor=0.8475,\n",
    "    n_epochs=40,\n",
    "    seed=seed,\n",
    "    log_each=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key feature of my implementation is that it is possible to create a feature vector for new user with history, without training whole system from scratch. How is it possible? I fix all weigths for the other users and items and train only weights for the new user. To understand it better, imagine that feature vectors for all users/items are embeddings in the neural network. Obviously, in one batch we do not train all embeddings, only those that are presented in the batch. Here is point is the same, each feature vector for user/item is an embedding of the ID, so for one user we can train only one embedding, other weights are kept fixed. This may leed to small performance degradation but will improve speed of training a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0, min MSE loss 7.902, curr MSE loss 7.902, last 2 epochs took 10.453 secs, elapsed 0.174 mins\n",
      "Epoch   2, min MSE loss 7.902, curr MSE loss 7.902, last 2 epochs took 5.052 secs, elapsed 0.258 mins\n",
      "Epoch   4, min MSE loss 7.902, curr MSE loss 7.902, last 2 epochs took 5.119 secs, elapsed 0.344 mins\n",
      "Epoch   6, min MSE loss 7.902, curr MSE loss 7.902, last 2 epochs took 5.480 secs, elapsed 0.435 mins\n",
      "Epoch   8, min MSE loss 7.902, curr MSE loss 7.902, last 2 epochs took 5.018 secs, elapsed 0.519 mins\n",
      "Epoch  10, min MSE loss 7.902, curr MSE loss 7.902, last 2 epochs took 5.024 secs, elapsed 0.602 mins\n",
      "Epoch  12, min MSE loss 7.902, curr MSE loss 7.902, last 2 epochs took 5.207 secs, elapsed 0.689 mins\n",
      "Epoch  14, min MSE loss 7.902, curr MSE loss 7.902, last 2 epochs took 5.568 secs, elapsed 0.782 mins\n",
      "Epoch  16, min MSE loss 7.902, curr MSE loss 7.902, last 2 epochs took 5.174 secs, elapsed 0.868 mins\n",
      "Epoch  18, min MSE loss 7.902, curr MSE loss 7.902, last 2 epochs took 5.150 secs, elapsed 0.954 mins\n",
      "Train RMSE :: 3.9352064289493867\n",
      "Working Wisdom: Top 10 Lists for Improving Your Business     :: 9.000\n",
      "Adam's Task: Calling Animals by Name (Common Reader Editions) :: 9.000\n",
      "Eyes Of Betrayal                                             :: 9.000\n",
      "The Brothers K                                               :: 9.000\n",
      "When I Get Free: A Novel                                     :: 9.000\n",
      "Heavy Weather                                                :: 9.000\n",
      "Vegetarian Cookbook (DK Living)                              :: 9.000\n",
      "Buffalo Bird Woman's Garden: Agriculture of the Hidatsa Indians (Borealis) :: 9.000\n",
      "Cromwell: Our Chief of Men                                   :: 9.000\n",
      "Conspiracy of Kindness: A Refreshing New Approach to Sharing the Love of Jesus With Others :: 9.000\n",
      "Cottage for Sale--Must Be Moved: A Woman Moves a House to Make a Home :: 9.000\n",
      "Learning to Wave: An Intimate Voyage into the Consciousness of Change :: 9.000\n",
      "The Loved and the Lost (MacMillan Paperback)                 :: 9.000\n",
      "Three Novels of Old New York                                 :: 9.000\n",
      "Hypershot                                                    :: 9.000\n",
      "The House of Mirth (Library of America)                      :: 9.000\n",
      "Konfetti                                                     :: 9.000\n",
      "Sculpting Her Body Perfect                                   :: 9.000\n",
      "Lonesome Song (Shep Harrington Small Town Mysteries)         :: 9.000\n",
      "Montana Spaces                                               :: 9.000\n",
      "Jeeves in the Offing (Wodehouse, P. G. Collector's Wodehouse.) :: 9.000\n",
      "Le Silence des agneaux                                       :: 9.000\n",
      "Fawn: The first year in the life of a red deer in New Zealand :: 9.000\n",
      "Dr. Isadore Rosenfeld's Breakthrough Health 2004: 167 Up-to-the Minute Medical Discoveries, Treatments, and Cures That Can Save Your Life, from America's Most Trusted Doctor! :: 9.000\n",
      "Dying Inside                                                 :: 9.000\n",
      "Sistemas Operativos - 5b: Edicion                            :: 9.000\n",
      "Illustrated Pepys                                            :: 9.000\n",
      "God's the One Who Thought of It First (Happy Day Book)       :: 9.000\n",
      "Lettre a une droite maladroite                               :: 9.000\n",
      "Daniel Faces the Lion (Beginners Bible Very First Adventures) :: 9.000\n",
      "Dominique                                                    :: 9.000\n",
      "Twist Of Fate                                                :: 9.000\n"
     ]
    }
   ],
   "source": [
    "lotr = ratings_df[ratings_df.title == 'Lord of the Rings Trilogy']\n",
    "prediction = m.predict_new_user_with_history(\n",
    "    history={lotr.book_id.unique()[0]: 10},\n",
    "    round=False,\n",
    "    lam=1,\n",
    "    lr=0.01,\n",
    "    lr_factor=0.8,\n",
    "    n_epochs=20,\n",
    "    seed=seed,\n",
    "    log_each=2,\n",
    ")\n",
    "\n",
    "prediction_title = []\n",
    "for i, val in enumerate(prediction):\n",
    "    if val < 9:\n",
    "        continue\n",
    "    title = ratings_df[ratings_df.book_id == i].title.unique()[0]\n",
    "    prediction_title.append([title, val])\n",
    "\n",
    "prediction_title.sort(key=lambda x: x[1])\n",
    "\n",
    "for t, v in prediction_title[:50]:\n",
    "    if t == 'Unknown Book':\n",
    "        continue\n",
    "    print(f'{t:60} :: {v:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-venv)",
   "language": "python",
   "name": "pytorch-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
